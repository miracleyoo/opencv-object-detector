{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Zhongyang Zhang\n",
    "\n",
    "Email : mirakuruyoo@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from skimage.feature import hog\n",
    "from skimage.feature import haar_like_feature\n",
    "from skimage.feature import local_binary_pattern as lbp\n",
    "from skimage.io import imread\n",
    "from skimage.transform import pyramid_gaussian, integral_image\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs \n",
    "Please change the PROJECT_ID term every time when excuting a new experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self, project_id=None):\n",
    "        \n",
    "        # General Config\n",
    "        self.DES_TYPE = \"HOG\"\n",
    "        self.CLF_TYPE = \"LIN_SVM\"\n",
    "        if project_id:\n",
    "            self.PROJECT_ID = project_id\n",
    "        else:\n",
    "            self.PROJECT_ID = \"New_Vedio_New_Neg\" + self.DES_TYPE + '_' + self.CLF_TYPE\n",
    "        self.THRESHOLD = 0.3\n",
    "        self.DOWNSCALE = 1.25\n",
    "        \n",
    "        # Pathes\n",
    "        self.update_names()\n",
    "        \n",
    "        # HOG Features\n",
    "        self.MIN_WDW_SIZE = [64, 64]\n",
    "        self.STEP_SIZE = [12, 12]\n",
    "        self.ORIENTATIONS = 9\n",
    "        self.PIXELS_PER_CELL = [3, 3]\n",
    "        self.CELLS_PER_BLOCK = [3, 3]\n",
    "        self.VISUALIZE = False\n",
    "        self.NORMALIZE = True\n",
    "        self.IF_PRINT  = False\n",
    "        self.KEEP_FEAT = False\n",
    "        \n",
    "        # LBP Features\n",
    "        self.LBP_RADIUS = 3\n",
    "        self.LBP_POINTS = 8 * self.LBP_RADIUS\n",
    "        \n",
    "        self.mk_new_dirs()\n",
    "        \n",
    "    def mk_new_dirs(self):\n",
    "        for ph in self.DIR_PATHS.values():\n",
    "            if not os.path.exists(ph):\n",
    "                os.makedirs(ph)\n",
    "                print(\"==> Directory Tree\",ph,\"created\")\n",
    "                \n",
    "    def update_names(self):\n",
    "        # Pathes\n",
    "        self.DIR_PATHS = {\n",
    "            \"POS_FEAT_PH\"    : os.path.join(\"./source/features\", self.PROJECT_ID,\"pos\"),\n",
    "            \"NEG_FEAT_PH\"    : os.path.join(\"./source/features\", self.PROJECT_ID,\"neg\"),\n",
    "            \"MODEL_DIR_PH\"   : os.path.join(\"./source/models\", self.PROJECT_ID),\n",
    "            \"PRED_SAVE_PH\"   : os.path.join(\"./source/predictions\", self.PROJECT_ID),\n",
    "            \"POS_IMG_PH\"     : \"./source/images/pos\",\n",
    "            \"NEG_IMG_PH\"     : \"./source/images/neg\",\n",
    "            \"TEST_IMG_DIR_PH\": \"./source/test_images\"}\n",
    "        self.MODEL_PH = os.path.join(self.DIR_PATHS[\"MODEL_DIR_PH\"], \"svm.model\")\n",
    "        self.TEST_IMG_PH = os.path.join(self.DIR_PATHS[\"TEST_IMG_DIR_PH\"], \"test.jpg\")\n",
    "                \n",
    "# args = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image, args=args):\n",
    "    if args.DES_TYPE == \"HOG\":\n",
    "        fd = hog(image, block_norm='L2', pixels_per_cell=args.PIXELS_PER_CELL)\n",
    "    elif args.DES_TYPE == \"LBP\":\n",
    "        fd = lbp(image, args.LBP_POINTS, args.LBP_RADIUS)\n",
    "    elif args.DES_TYPE == \"HAAR\":\n",
    "        fd = haar_like_feature(integral_image(image), 0, 0, 5, 5, 'type-3-x')\n",
    "    else:\n",
    "        raise KeyError(\"==> The Processing method does not exist!\")\n",
    "    return fd\n",
    "\n",
    "def extract_features(args=args):\n",
    "    if os.path.exists(args.DIR_PATHS[\"POS_FEAT_PH\"]):\n",
    "        shutil.rmtree(args.DIR_PATHS[\"POS_FEAT_PH\"])\n",
    "    if os.path.exists(args.DIR_PATHS[\"NEG_FEAT_PH\"]):\n",
    "        shutil.rmtree(args.DIR_PATHS[\"NEG_FEAT_PH\"])\n",
    "    os.makedirs(args.DIR_PATHS[\"POS_FEAT_PH\"])\n",
    "    os.makedirs(args.DIR_PATHS[\"NEG_FEAT_PH\"])\n",
    "    \n",
    "    print(\"==> Calculating the descriptors for the positive samples and saving them\")\n",
    "    for im_path in tqdm(glob.glob(os.path.join(args.DIR_PATHS[\"POS_IMG_PH\"], \"*\"))):\n",
    "        im = imread(im_path, as_grey=True)\n",
    "        fd = process_image(im)\n",
    "        fd_name = os.path.split(im_path)[1].split(\".\")[0] + \".feat\"\n",
    "        fd_path = os.path.join(args.DIR_PATHS[\"POS_FEAT_PH\"], fd_name)\n",
    "        joblib.dump(fd, fd_path)\n",
    "    print(\"==> Positive features saved in {}\".format(args.DIR_PATHS[\"POS_FEAT_PH\"]))\n",
    "\n",
    "    print(\"==> Calculating the descriptors for the negative samples and saving them\")\n",
    "    for im_path in tqdm(glob.glob(os.path.join(args.DIR_PATHS[\"NEG_IMG_PH\"], \"*\"))):\n",
    "        im = imread(im_path, as_grey=True)\n",
    "        fd = process_image(im)\n",
    "        fd_name = os.path.split(im_path)[1].split(\".\")[0] + \".feat\"\n",
    "        fd_path = os.path.join(args.DIR_PATHS[\"NEG_FEAT_PH\"], fd_name)\n",
    "        joblib.dump(fd, fd_path)\n",
    "    print(\"==> Negative features saved in {}\".format(args.DIR_PATHS[\"NEG_FEAT_PH\"]))\n",
    "    print(\"==> Completed calculating features from training images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_classifier(args=args):\n",
    "    fds = []\n",
    "    labels = []\n",
    "    print(\"==> Loading the positive features\")\n",
    "    for feat_path in tqdm(glob.glob(os.path.join(args.DIR_PATHS[\"POS_FEAT_PH\"], \"*.feat\"))):\n",
    "        fd = joblib.load(feat_path)\n",
    "        fds.append(fd.reshape(-1))\n",
    "        labels.append(1)\n",
    "\n",
    "    print(\"==> Load the negative features\")\n",
    "    for feat_path in tqdm(glob.glob(os.path.join(args.DIR_PATHS[\"NEG_FEAT_PH\"], \"*.feat\"))):\n",
    "        fd = joblib.load(feat_path)\n",
    "        fds.append(fd.reshape(-1))\n",
    "        labels.append(0)\n",
    "\n",
    "    if args.CLF_TYPE is \"LIN_SVM\":\n",
    "        clf = LinearSVC()\n",
    "        print(\"==> Training a Linear SVM Classifier\")\n",
    "        clf.fit(fds, labels)\n",
    "        joblib.dump(clf, args.MODEL_PH)\n",
    "        print(\"==> Classifier saved to {}\".format(args.MODEL_PH))\n",
    "    elif args.CLF_TYPE is \"MLP\":\n",
    "        clf = MLPClassifier(solver='lbfgs', alpha=1e-4, hidden_layer_sizes=(16, 32, 64), random_state=1)\n",
    "        print(\"==> Training a Multi Layer Classifier\")\n",
    "        clf.fit(fds, labels)\n",
    "        joblib.dump(clf, args.MODEL_PH)\n",
    "        print(\"==> Classifier saved to {}\".format(args.MODEL_PH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Non-Maxima Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def overlapping_area(detection_1, detection_2):\n",
    "    \"\"\"\n",
    "        Function to calculate overlapping area'si\n",
    "        `detection_1` and `detection_2` are 2 detections whose area\n",
    "        of overlap needs to be found out.\n",
    "        Each detection is list in the format ->\n",
    "        [x-top-left, y-top-left, confidence-of-detections, width-of-detection, height-of-detection]\n",
    "        The function returns a value between 0 and 1,\n",
    "        which represents the area of overlap.\n",
    "        0 is no overlap and 1 is complete overlap.\n",
    "        Area calculated from ->\n",
    "        http://math.stackexchange.com/questions/99565/simplest-way-to-calculate-the-intersect-area-of-two-rectangles\n",
    "    \"\"\"\n",
    "    # Calculate the x-y co-ordinates of the rectangles\n",
    "    x1_tl = detection_1[0]\n",
    "    x2_tl = detection_2[0]\n",
    "    x1_br = detection_1[0] + detection_1[3]\n",
    "    x2_br = detection_2[0] + detection_2[3]\n",
    "    y1_tl = detection_1[1]\n",
    "    y2_tl = detection_2[1]\n",
    "    y1_br = detection_1[1] + detection_1[4]\n",
    "    y2_br = detection_2[1] + detection_2[4]\n",
    "    # Calculate the overlapping Area\n",
    "    x_overlap = max(0, min(x1_br, x2_br) - max(x1_tl, x2_tl))\n",
    "    y_overlap = max(0, min(y1_br, y2_br) - max(y1_tl, y2_tl))\n",
    "    overlap_area = x_overlap * y_overlap\n",
    "    area_1 = detection_1[3] * detection_2[4]\n",
    "    area_2 = detection_2[3] * detection_2[4]\n",
    "    total_area = area_1 + area_2 - overlap_area\n",
    "    return overlap_area / float(total_area)\n",
    "\n",
    "\n",
    "def nms(detections, threshold=.5):\n",
    "    \"\"\"\n",
    "        This function performs Non-Maxima Suppression.\n",
    "        `detections` consists of a list of detections.\n",
    "        Each detection is in the format ->\n",
    "        [x-top-left, y-top-left, confidence-of-detections, width-of-detection, height-of-detection]\n",
    "        If the area of overlap is greater than the `threshold`,\n",
    "        the area with the lower confidence score is removed.\n",
    "        The output is a list of detections.\n",
    "    \"\"\"\n",
    "    if len(detections) == 0:\n",
    "        return []\n",
    "    # Sort the detections based on confidence score\n",
    "    detections = sorted(detections, key=lambda detections: detections[2],\n",
    "                        reverse=True)\n",
    "    new_detections = [] # Unique detections will be appended to this list\n",
    "    new_detections.append(detections[0]) # Append the first detection\n",
    "    del detections[0] # Remove the detection from the original list\n",
    "    \"\"\"\n",
    "        For each detection, calculate the overlapping area\n",
    "        and if area of overlap is less than the threshold set\n",
    "        for the detections in `new_detections`, append the \n",
    "        detection to `new_detections`.\n",
    "        In either case, remove the detection from `detections` list.\n",
    "    \"\"\"\n",
    "    for index, detection in enumerate(detections):\n",
    "        for new_detection in new_detections:\n",
    "            if overlapping_area(detection, new_detection) > threshold:\n",
    "                del detections[index]\n",
    "                break\n",
    "        else:\n",
    "            new_detections.append(detection)\n",
    "            del detections[index]\n",
    "    return new_detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_by_short(img, short_len=256):\n",
    "    print(img.size)\n",
    "    (x, y) = img.size\n",
    "    if x > y:\n",
    "        y_s = short_len\n",
    "        x_s = int(x * y_s / y)\n",
    "        img = img.resize((x_s, y_s))\n",
    "    else:\n",
    "        x_s = short_len\n",
    "        y_s = int(y * x_s / x)\n",
    "        img = img.resize((x_s, y_s))\n",
    "    return img\n",
    "\n",
    "\n",
    "def sliding_window(image, window_size, step_size):\n",
    "    \"\"\"\n",
    "        This function returns a patch of the input image `image` of size equal\n",
    "        to `window_size`. The first image returned top-left co-ordinates (0, 0)\n",
    "        and are increment in both x and y directions by the `step_size` supplied.\n",
    "        So, the input parameters are -\n",
    "        * `image` - Input Image\n",
    "        * `window_size` - Size of Sliding Window\n",
    "        * `step_size` - Incremented Size of Window\n",
    "\n",
    "        The function returns a tuple -\n",
    "        (x, y, im_window)\n",
    "        where\n",
    "        * x is the top-left x co-ordinate\n",
    "        * y is the top-left y co-ordinate\n",
    "        * im_window is the sliding window image\n",
    "    \"\"\"\n",
    "    for y in range(0, image.shape[0], step_size[1]):\n",
    "        for x in range(0, image.shape[1], step_size[0]):\n",
    "            yield (x, y, image[y:y + window_size[1], x:x + window_size[0]])\n",
    "\n",
    "\n",
    "def test_classifier(args=args):\n",
    "    for im_path in [os.path.join(args.DIR_PATHS[\"TEST_IMG_DIR_PH\"], i) for i in os.listdir(args.DIR_PATHS[\"TEST_IMG_DIR_PH\"]) if not i.startswith('.')]:\n",
    "        # Read the Image\n",
    "        im = Image.open(im_path).convert('L')\n",
    "        im = np.array(resize_by_short(im))\n",
    "\n",
    "        clf = joblib.load(args.MODEL_PH) # Load the classifier\n",
    "        detections = [] # List to store the detections\n",
    "        scale = 0 # The current scale of the image\n",
    "\n",
    "        # Downscale the image and iterate\n",
    "        for im_scaled in pyramid_gaussian(im, downscale=args.DOWNSCALE):\n",
    "            cd = [] # This list contains detections at the current scale\n",
    "            # If the width or height of the scaled image is less than\n",
    "            # the width or height of the window, then end the iterations.\n",
    "            if im_scaled.shape[0] < args.MIN_WDW_SIZE[1] or im_scaled.shape[1] < args.MIN_WDW_SIZE[0]:\n",
    "                break\n",
    "            for (x, y, im_window) in sliding_window(im_scaled, args.MIN_WDW_SIZE, args.STEP_SIZE):\n",
    "                if im_window.shape[0] != args.MIN_WDW_SIZE[1] or im_window.shape[1] != args.MIN_WDW_SIZE[0]:\n",
    "                    continue\n",
    "                # Calculate the HOG features\n",
    "                fd = process_image(im_window).reshape([1, -1])\n",
    "                pred = clf.predict(fd)\n",
    "                if pred == 1:\n",
    "                    if args.IF_PRINT: print(\"==> Detection:: Location -> ({}, {})\".format(x, y))\n",
    "                    if args.CLF_TYPE is \"LIN_SVM\":\n",
    "                        if args.IF_PRINT: print(\"==> Scale ->  {} Confidence Score {} \\n\".format(scale, clf.decision_function(fd)))\n",
    "                        detections.append((x, y, clf.decision_function(fd),\n",
    "                                           int(args.MIN_WDW_SIZE[0] * (args.DOWNSCALE ** scale)),\n",
    "                                           int(args.MIN_WDW_SIZE[1] * (args.DOWNSCALE ** scale))))\n",
    "                    elif args.CLF_TYPE is \"MLP\":\n",
    "                        if args.IF_PRINT: print(\"==> Scale ->  {} Confidence Score {} \\n\".format(scale, clf.predict_proba(fd)[0][1]))#clf.decision_function(fd)))\n",
    "                        detections.append((x, y, clf.predict_proba(fd)[0][1],\n",
    "                                           int(args.MIN_WDW_SIZE[0] * (args.DOWNSCALE ** scale)),\n",
    "                                           int(args.MIN_WDW_SIZE[1] * (args.DOWNSCALE ** scale))))\n",
    "                    cd.append(detections[-1])\n",
    "\n",
    "                # If visualize is set to true, display the working of the sliding window\n",
    "                if args.VISUALIZE:\n",
    "                    clone = im_scaled.copy()\n",
    "                    for x1, y1, _, _, _ in cd:\n",
    "                        # Draw the detections at this scale\n",
    "                        cv2.rectangle(clone, (x1, y1), (x1 + im_window.shape[1], y1 +\n",
    "                                                        im_window.shape[0]), (0, 0, 0), thickness=2)\n",
    "                    cv2.rectangle(clone, (x, y), (x + im_window.shape[1], y +\n",
    "                                                  im_window.shape[0]), (255, 255, 255), thickness=2)\n",
    "                    cv2.imshow(\"Sliding Window in Progress\", clone)\n",
    "                    cv2.waitKey(30)\n",
    "\n",
    "            # Move the the next scale\n",
    "            scale += 1\n",
    "\n",
    "        # Display the results before performing NMS\n",
    "        clone = im.copy()\n",
    "\n",
    "        # Draw the detections\n",
    "        for (x_tl, y_tl, _, w, h) in detections:\n",
    "            cv2.rectangle(im, (x_tl, y_tl), (x_tl + w, y_tl + h), (0, 0, 0), thickness=2)\n",
    "\n",
    "        detections_fin = nms(detections, args.THRESHOLD) # Perform Non Maxima Suppression\n",
    "\n",
    "        # Display the results after performing NMS\n",
    "        for (x_tl, y_tl, _, w, h) in detections_fin:\n",
    "            # Draw the detections\n",
    "            cv2.rectangle(clone, (x_tl, y_tl), (x_tl + w, y_tl + h), (0, 0, 0), thickness=2)\n",
    "            \n",
    "        if args.VISUALIZE:\n",
    "            cv2.imshow(\"Final Detections after applying NMS\", clone)\n",
    "            \n",
    "#         print(os.path.split(im_path))\n",
    "        print(os.path.join(args.DIR_PATHS['PRED_SAVE_PH'], os.path.split(im_path)[1]))\n",
    "        cv2.imwrite(os.path.join(args.DIR_PATHS['PRED_SAVE_PH'], os.path.split(im_path)[1]), clone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract_features()\n",
    "# train_classifier()\n",
    "# test_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9731 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 12/9731 [00:00<01:23, 116.30it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3 {'POS_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/pos', 'NEG_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/neg', 'MODEL_DIR_PH': './source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3', 'PRED_SAVE_PH': './source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3', 'POS_IMG_PH': './source/images/pos', 'NEG_IMG_PH': './source/images/neg', 'TEST_IMG_DIR_PH': './source/test_images'}\n",
      "==> Calculating the descriptors for the positive samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 23/9731 [00:00<01:26, 111.60it/s]\u001b[A\n",
      "  0%|          | 35/9731 [00:00<01:27, 111.12it/s]\u001b[A\n",
      "  0%|          | 47/9731 [00:00<01:26, 111.93it/s]\u001b[A\n",
      "  1%|          | 59/9731 [00:00<01:26, 111.57it/s]\u001b[A\n",
      "  1%|          | 71/9731 [00:00<01:26, 111.67it/s]\u001b[A\n",
      "  1%|          | 83/9731 [00:00<01:26, 112.11it/s]\u001b[A\n",
      "  1%|          | 95/9731 [00:00<01:26, 111.79it/s]\u001b[A\n",
      "  1%|          | 107/9731 [00:00<01:26, 111.77it/s]\u001b[A\n",
      "  1%|          | 119/9731 [00:01<01:26, 111.64it/s]\u001b[A\n",
      "  1%|▏         | 130/9731 [00:01<01:26, 110.52it/s]\u001b[A\n",
      "  1%|▏         | 141/9731 [00:01<01:27, 110.12it/s]\u001b[A\n",
      "  2%|▏         | 153/9731 [00:01<01:26, 110.20it/s]\u001b[A\n",
      "  2%|▏         | 165/9731 [00:01<01:26, 110.27it/s]\u001b[A\n",
      "  2%|▏         | 176/9731 [00:01<01:26, 110.00it/s]\u001b[A\n",
      "  2%|▏         | 187/9731 [00:01<01:26, 109.93it/s]\u001b[A\n",
      "  2%|▏         | 198/9731 [00:01<01:27, 108.93it/s]\u001b[A\n",
      "  2%|▏         | 209/9731 [00:01<01:27, 108.71it/s]\u001b[A\n",
      "  2%|▏         | 220/9731 [00:02<01:27, 108.44it/s]\u001b[A\n",
      "  2%|▏         | 231/9731 [00:02<01:27, 108.05it/s]\u001b[A\n",
      "  2%|▏         | 242/9731 [00:02<01:27, 108.02it/s]\u001b[A\n",
      "  3%|▎         | 254/9731 [00:02<01:27, 108.10it/s]\u001b[A\n",
      "  3%|▎         | 266/9731 [00:02<01:27, 108.42it/s]\u001b[A\n",
      "  3%|▎         | 277/9731 [00:02<01:27, 108.44it/s]\u001b[A\n",
      "  3%|▎         | 289/9731 [00:02<01:26, 108.71it/s]\u001b[A\n",
      "  3%|▎         | 301/9731 [00:02<01:26, 108.91it/s]\u001b[A\n",
      "  3%|▎         | 313/9731 [00:02<01:26, 109.14it/s]\u001b[A\n",
      "  3%|▎         | 325/9731 [00:02<01:25, 109.43it/s]\u001b[A\n",
      "  3%|▎         | 337/9731 [00:03<01:25, 109.42it/s]\u001b[A\n",
      "  4%|▎         | 349/9731 [00:03<01:25, 109.50it/s]\u001b[A\n",
      "Exception in thread Thread-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/miracle/anaconda2/envs/py3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/miracle/anaconda2/envs/py3/lib/python3.6/site-packages/tqdm/_monitor.py\", line 63, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/Users/miracle/anaconda2/envs/py3/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "100%|██████████| 9731/9731 [01:32<00:00, 104.89it/s]\n",
      "  1%|          | 11/2000 [00:00<00:18, 106.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Positive features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/pos\n",
      "==> Calculating the descriptors for the negative samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:19<00:00, 104.29it/s]\n",
      "100%|██████████| 336/336 [00:00<00:00, 2339.65it/s]\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Negative features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/neg\n",
      "==> Completed calculating features from training images\n",
      "==> Loading the positive features\n",
      "==> Load the negative features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 2359.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training a Linear SVM Classifier\n",
      "==> Classifier saved to ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/svm.model\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/test_9.JPG\n",
      "(1920, 1920)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/test_8.JPG\n",
      "(2576, 1932)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/test_3.JPG\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/test_2.jpg\n",
      "(1280, 960)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/test_0.JPG\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/test_1.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/pos_test_1.jpg\n",
      "(321, 246)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/test_5.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/test_4.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/pos_test_0.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/pos_test_2.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/test_6.jpg\n",
      "(2320, 2316)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/test_7.jpg\n",
      "(64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/9731 [00:00<01:30, 107.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/pos_test_3.jpg\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3 {'POS_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/pos', 'NEG_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/neg', 'MODEL_DIR_PH': './source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3', 'PRED_SAVE_PH': './source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3', 'POS_IMG_PH': './source/images/pos', 'NEG_IMG_PH': './source/images/neg', 'TEST_IMG_DIR_PH': './source/test_images'}\n",
      "==> Calculating the descriptors for the positive samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9731/9731 [01:27<00:00, 110.82it/s]\n",
      "  1%|          | 11/2000 [00:00<00:19, 104.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Positive features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/pos\n",
      "==> Calculating the descriptors for the negative samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:18<00:00, 105.92it/s]\n",
      "100%|██████████| 336/336 [00:00<00:00, 2321.39it/s]\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Negative features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/neg\n",
      "==> Completed calculating features from training images\n",
      "==> Loading the positive features\n",
      "==> Load the negative features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 2359.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training a Linear SVM Classifier\n",
      "==> Classifier saved to ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/svm.model\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/test_9.JPG\n",
      "(1920, 1920)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/test_8.JPG\n",
      "(2576, 1932)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/test_3.JPG\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/test_2.jpg\n",
      "(1280, 960)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/test_0.JPG\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/test_1.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/pos_test_1.jpg\n",
      "(321, 246)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/test_5.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/test_4.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/pos_test_0.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/pos_test_2.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/test_6.jpg\n",
      "(2320, 2316)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/test_7.jpg\n",
      "(64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/9731 [00:00<01:29, 109.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/pos_test_3.jpg\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3 {'POS_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3/pos', 'NEG_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3/neg', 'MODEL_DIR_PH': './source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3', 'PRED_SAVE_PH': './source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3', 'POS_IMG_PH': './source/images/pos', 'NEG_IMG_PH': './source/images/neg', 'TEST_IMG_DIR_PH': './source/test_images'}\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3/pos created\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3/neg created\n",
      "==> Directory Tree ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3 created\n",
      "==> Directory Tree ./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3 created\n",
      "==> Calculating the descriptors for the positive samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9731/9731 [01:28<00:00, 109.79it/s]\n",
      "  1%|          | 11/2000 [00:00<00:18, 106.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Positive features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3/pos\n",
      "==> Calculating the descriptors for the negative samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:18<00:00, 106.63it/s]\n",
      " 71%|███████   | 238/336 [00:00<00:00, 1180.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Negative features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3/neg\n",
      "==> Completed calculating features from training images\n",
      "==> Loading the positive features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [00:00<00:00, 1095.02it/s]\n",
      "  9%|▉         | 176/2000 [00:00<00:01, 1756.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Load the negative features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1049.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training a Linear SVM Classifier\n",
      "==> Classifier saved to ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3/svm.model\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3/test_9.JPG\n",
      "(1920, 1920)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3/test_8.JPG\n",
      "(2576, 1932)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3/test_3.JPG\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3/test_2.jpg\n",
      "(1280, 960)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3/test_0.JPG\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3/test_1.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3/pos_test_1.jpg\n",
      "(321, 246)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3/test_5.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3/test_4.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3/pos_test_0.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3/pos_test_2.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3/test_6.jpg\n",
      "(2320, 2316)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3/test_7.jpg\n",
      "(64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/9731 [00:00<01:29, 108.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3/pos_test_3.jpg\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_3\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3 {'POS_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3/pos', 'NEG_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3/neg', 'MODEL_DIR_PH': './source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3', 'PRED_SAVE_PH': './source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3', 'POS_IMG_PH': './source/images/pos', 'NEG_IMG_PH': './source/images/neg', 'TEST_IMG_DIR_PH': './source/test_images'}\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3/pos created\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3/neg created\n",
      "==> Directory Tree ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3 created\n",
      "==> Directory Tree ./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3 created\n",
      "==> Calculating the descriptors for the positive samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9731/9731 [01:27<00:00, 110.61it/s]\n",
      "  1%|          | 11/2000 [00:00<00:18, 107.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Positive features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3/pos\n",
      "==> Calculating the descriptors for the negative samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:18<00:00, 105.38it/s]\n",
      "100%|██████████| 336/336 [00:00<00:00, 2334.73it/s]\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Negative features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3/neg\n",
      "==> Completed calculating features from training images\n",
      "==> Loading the positive features\n",
      "==> Load the negative features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1238.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training a Linear SVM Classifier\n",
      "==> Classifier saved to ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3/svm.model\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3/test_9.JPG\n",
      "(1920, 1920)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3/test_8.JPG\n",
      "(2576, 1932)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3/test_3.JPG\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3/test_2.jpg\n",
      "(1280, 960)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3/test_0.JPG\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3/test_1.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3/pos_test_1.jpg\n",
      "(321, 246)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3/test_5.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3/test_4.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3/pos_test_0.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3/pos_test_2.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3/test_6.jpg\n",
      "(2320, 2316)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3/test_7.jpg\n",
      "(64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/9731 [00:00<01:29, 108.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3/pos_test_3.jpg\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_3\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3 {'POS_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3/pos', 'NEG_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3/neg', 'MODEL_DIR_PH': './source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3', 'PRED_SAVE_PH': './source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3', 'POS_IMG_PH': './source/images/pos', 'NEG_IMG_PH': './source/images/neg', 'TEST_IMG_DIR_PH': './source/test_images'}\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3/pos created\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3/neg created\n",
      "==> Directory Tree ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3 created\n",
      "==> Directory Tree ./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3 created\n",
      "==> Calculating the descriptors for the positive samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9731/9731 [01:26<00:00, 111.91it/s]\n",
      "  1%|          | 11/2000 [00:00<00:18, 109.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Positive features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3/pos\n",
      "==> Calculating the descriptors for the negative samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:18<00:00, 107.68it/s]\n",
      "100%|██████████| 336/336 [00:00<00:00, 2401.52it/s]\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Negative features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3/neg\n",
      "==> Completed calculating features from training images\n",
      "==> Loading the positive features\n",
      "==> Load the negative features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 2363.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training a Linear SVM Classifier\n",
      "==> Classifier saved to ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3/svm.model\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3/test_9.JPG\n",
      "(1920, 1920)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3/test_8.JPG\n",
      "(2576, 1932)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3/test_3.JPG\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3/test_2.jpg\n",
      "(1280, 960)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3/test_0.JPG\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3/test_1.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3/pos_test_1.jpg\n",
      "(321, 246)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3/test_5.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3/test_4.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3/pos_test_0.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3/pos_test_2.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3/test_6.jpg\n",
      "(2320, 2316)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3/test_7.jpg\n",
      "(64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/9731 [00:00<01:35, 102.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3/pos_test_3.jpg\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_3\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3 {'POS_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3/pos', 'NEG_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3/neg', 'MODEL_DIR_PH': './source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3', 'PRED_SAVE_PH': './source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3', 'POS_IMG_PH': './source/images/pos', 'NEG_IMG_PH': './source/images/neg', 'TEST_IMG_DIR_PH': './source/test_images'}\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3/pos created\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3/neg created\n",
      "==> Directory Tree ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3 created\n",
      "==> Directory Tree ./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3 created\n",
      "==> Calculating the descriptors for the positive samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9731/9731 [01:29<00:00, 108.38it/s]\n",
      "  1%|          | 11/2000 [00:00<00:18, 109.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Positive features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3/pos\n",
      "==> Calculating the descriptors for the negative samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:19<00:00, 102.13it/s]\n",
      " 32%|███▏      | 109/336 [00:00<00:00, 1087.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Negative features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3/neg\n",
      "==> Completed calculating features from training images\n",
      "==> Loading the positive features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [00:00<00:00, 952.83it/s] \n",
      "  7%|▋         | 149/2000 [00:00<00:01, 1480.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Load the negative features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1035.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training a Linear SVM Classifier\n",
      "==> Classifier saved to ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3/svm.model\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3/test_9.JPG\n",
      "(1920, 1920)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3/test_8.JPG\n",
      "(2576, 1932)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3/test_3.JPG\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3/test_2.jpg\n",
      "(1280, 960)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3/test_0.JPG\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3/test_1.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3/pos_test_1.jpg\n",
      "(321, 246)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3/test_5.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3/test_4.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3/pos_test_0.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3/pos_test_2.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3/test_6.jpg\n",
      "(2320, 2316)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3/test_7.jpg\n",
      "(64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/9731 [00:00<01:37, 100.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3/pos_test_3.jpg\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_3\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3 {'POS_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3/pos', 'NEG_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3/neg', 'MODEL_DIR_PH': './source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3', 'PRED_SAVE_PH': './source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3', 'POS_IMG_PH': './source/images/pos', 'NEG_IMG_PH': './source/images/neg', 'TEST_IMG_DIR_PH': './source/test_images'}\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3/pos created\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3/neg created\n",
      "==> Directory Tree ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3 created\n",
      "==> Directory Tree ./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3 created\n",
      "==> Calculating the descriptors for the positive samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9731/9731 [01:27<00:00, 111.32it/s]\n",
      "  1%|          | 12/2000 [00:00<00:17, 112.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Positive features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3/pos\n",
      "==> Calculating the descriptors for the negative samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:19<00:00, 105.17it/s]\n",
      "100%|██████████| 336/336 [00:00<00:00, 2272.85it/s]\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Negative features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3/neg\n",
      "==> Completed calculating features from training images\n",
      "==> Loading the positive features\n",
      "==> Load the negative features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 2242.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training a Linear SVM Classifier\n",
      "==> Classifier saved to ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3/svm.model\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3/test_9.JPG\n",
      "(1920, 1920)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3/test_8.JPG\n",
      "(2576, 1932)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3/test_3.JPG\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3/test_2.jpg\n",
      "(1280, 960)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3/test_0.JPG\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3/test_1.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3/pos_test_1.jpg\n",
      "(321, 246)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3/test_5.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3/test_4.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3/pos_test_0.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3/pos_test_2.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3/test_6.jpg\n",
      "(2320, 2316)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3/test_7.jpg\n",
      "(64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/9731 [00:00<01:25, 114.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3/pos_test_3.jpg\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_9_PPC_3\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4 {'POS_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4/pos', 'NEG_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4/neg', 'MODEL_DIR_PH': './source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4', 'PRED_SAVE_PH': './source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4', 'POS_IMG_PH': './source/images/pos', 'NEG_IMG_PH': './source/images/neg', 'TEST_IMG_DIR_PH': './source/test_images'}\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4/pos created\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4/neg created\n",
      "==> Directory Tree ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4 created\n",
      "==> Directory Tree ./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4 created\n",
      "==> Calculating the descriptors for the positive samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9731/9731 [01:30<00:00, 107.49it/s]\n",
      "  1%|          | 12/2000 [00:00<00:17, 111.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Positive features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4/pos\n",
      "==> Calculating the descriptors for the negative samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:22<00:00, 90.10it/s] \n",
      "100%|██████████| 336/336 [00:00<00:00, 2351.00it/s]\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Negative features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4/neg\n",
      "==> Completed calculating features from training images\n",
      "==> Loading the positive features\n",
      "==> Load the negative features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 2390.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training a Linear SVM Classifier\n",
      "==> Classifier saved to ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4/svm.model\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4/test_9.JPG\n",
      "(1920, 1920)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4/test_8.JPG\n",
      "(2576, 1932)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4/test_3.JPG\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4/test_2.jpg\n",
      "(1280, 960)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4/test_0.JPG\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4/test_1.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4/pos_test_1.jpg\n",
      "(321, 246)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4/test_5.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4/test_4.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4/pos_test_0.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4/pos_test_2.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4/test_6.jpg\n",
      "(2320, 2316)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4/test_7.jpg\n",
      "(64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/9731 [00:00<01:33, 103.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4/pos_test_3.jpg\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_4\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4 {'POS_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4/pos', 'NEG_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4/neg', 'MODEL_DIR_PH': './source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4', 'PRED_SAVE_PH': './source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4', 'POS_IMG_PH': './source/images/pos', 'NEG_IMG_PH': './source/images/neg', 'TEST_IMG_DIR_PH': './source/test_images'}\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4/pos created\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4/neg created\n",
      "==> Directory Tree ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4 created\n",
      "==> Directory Tree ./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4 created\n",
      "==> Calculating the descriptors for the positive samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9731/9731 [01:36<00:00, 101.09it/s]\n",
      "  1%|          | 12/2000 [00:00<00:17, 114.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Positive features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4/pos\n",
      "==> Calculating the descriptors for the negative samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:18<00:00, 108.73it/s]\n",
      "100%|██████████| 336/336 [00:00<00:00, 2343.81it/s]\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Negative features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4/neg\n",
      "==> Completed calculating features from training images\n",
      "==> Loading the positive features\n",
      "==> Load the negative features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 2327.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training a Linear SVM Classifier\n",
      "==> Classifier saved to ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4/svm.model\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4/test_9.JPG\n",
      "(1920, 1920)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4/test_8.JPG\n",
      "(2576, 1932)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4/test_3.JPG\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4/test_2.jpg\n",
      "(1280, 960)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4/test_0.JPG\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4/test_1.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4/pos_test_1.jpg\n",
      "(321, 246)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4/test_5.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4/test_4.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4/pos_test_0.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4/pos_test_2.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4/test_6.jpg\n",
      "(2320, 2316)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4/test_7.jpg\n",
      "(64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/9731 [00:00<01:31, 105.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4/pos_test_3.jpg\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_4\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4 {'POS_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4/pos', 'NEG_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4/neg', 'MODEL_DIR_PH': './source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4', 'PRED_SAVE_PH': './source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4', 'POS_IMG_PH': './source/images/pos', 'NEG_IMG_PH': './source/images/neg', 'TEST_IMG_DIR_PH': './source/test_images'}\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4/pos created\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4/neg created\n",
      "==> Directory Tree ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4 created\n",
      "==> Directory Tree ./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4 created\n",
      "==> Calculating the descriptors for the positive samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9731/9731 [01:35<00:00, 102.37it/s]\n",
      "  1%|          | 12/2000 [00:00<00:17, 110.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Positive features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4/pos\n",
      "==> Calculating the descriptors for the negative samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:18<00:00, 109.86it/s]\n",
      "100%|██████████| 336/336 [00:00<00:00, 2303.40it/s]\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Negative features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4/neg\n",
      "==> Completed calculating features from training images\n",
      "==> Loading the positive features\n",
      "==> Load the negative features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 2316.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training a Linear SVM Classifier\n",
      "==> Classifier saved to ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4/svm.model\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4/test_9.JPG\n",
      "(1920, 1920)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4/test_8.JPG\n",
      "(2576, 1932)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4/test_3.JPG\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4/test_2.jpg\n",
      "(1280, 960)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4/test_0.JPG\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4/test_1.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4/pos_test_1.jpg\n",
      "(321, 246)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4/test_5.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4/test_4.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4/pos_test_0.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4/pos_test_2.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4/test_6.jpg\n",
      "(2320, 2316)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4/test_7.jpg\n",
      "(64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/9731 [00:00<01:23, 115.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4/pos_test_3.jpg\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_5_PPC_4\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4 {'POS_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4/pos', 'NEG_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4/neg', 'MODEL_DIR_PH': './source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4', 'PRED_SAVE_PH': './source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4', 'POS_IMG_PH': './source/images/pos', 'NEG_IMG_PH': './source/images/neg', 'TEST_IMG_DIR_PH': './source/test_images'}\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4/pos created\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4/neg created\n",
      "==> Directory Tree ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4 created\n",
      "==> Directory Tree ./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4 created\n",
      "==> Calculating the descriptors for the positive samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9731/9731 [01:29<00:00, 109.16it/s]\n",
      "  1%|          | 12/2000 [00:00<00:16, 119.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Positive features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4/pos\n",
      "==> Calculating the descriptors for the negative samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:18<00:00, 110.55it/s]\n",
      "100%|██████████| 336/336 [00:00<00:00, 2404.88it/s]\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Negative features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4/neg\n",
      "==> Completed calculating features from training images\n",
      "==> Loading the positive features\n",
      "==> Load the negative features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 2397.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training a Linear SVM Classifier\n",
      "==> Classifier saved to ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4/svm.model\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4/test_9.JPG\n",
      "(1920, 1920)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4/test_8.JPG\n",
      "(2576, 1932)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4/test_3.JPG\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4/test_2.jpg\n",
      "(1280, 960)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4/test_0.JPG\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4/test_1.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4/pos_test_1.jpg\n",
      "(321, 246)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4/test_5.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4/test_4.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4/pos_test_0.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4/pos_test_2.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4/test_6.jpg\n",
      "(2320, 2316)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4/test_7.jpg\n",
      "(64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/9731 [00:00<02:07, 76.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4/pos_test_3.jpg\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_6_PPC_4\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4 {'POS_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4/pos', 'NEG_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4/neg', 'MODEL_DIR_PH': './source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4', 'PRED_SAVE_PH': './source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4', 'POS_IMG_PH': './source/images/pos', 'NEG_IMG_PH': './source/images/neg', 'TEST_IMG_DIR_PH': './source/test_images'}\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4/pos created\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4/neg created\n",
      "==> Directory Tree ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4 created\n",
      "==> Directory Tree ./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4 created\n",
      "==> Calculating the descriptors for the positive samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9731/9731 [01:45<00:00, 91.89it/s]\n",
      "  0%|          | 6/2000 [00:00<00:34, 58.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Positive features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4/pos\n",
      "==> Calculating the descriptors for the negative samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:27<00:00, 72.64it/s]\n",
      " 25%|██▌       | 84/336 [00:00<00:00, 834.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Negative features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4/neg\n",
      "==> Completed calculating features from training images\n",
      "==> Loading the positive features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [00:00<00:00, 790.87it/s]\n",
      "  4%|▍         | 76/2000 [00:00<00:02, 746.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Load the negative features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 779.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training a Linear SVM Classifier\n",
      "==> Classifier saved to ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4/svm.model\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4/test_9.JPG\n",
      "(1920, 1920)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4/test_8.JPG\n",
      "(2576, 1932)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4/test_3.JPG\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4/test_2.jpg\n",
      "(1280, 960)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4/test_0.JPG\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4/test_1.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4/pos_test_1.jpg\n",
      "(321, 246)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4/test_5.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4/test_4.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4/pos_test_0.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4/pos_test_2.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4/test_6.jpg\n",
      "(2320, 2316)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4/test_7.jpg\n",
      "(64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/9731 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4/pos_test_3.jpg\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_7_PPC_4\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_4 {'POS_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_4/pos', 'NEG_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_4/neg', 'MODEL_DIR_PH': './source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_4', 'PRED_SAVE_PH': './source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_4', 'POS_IMG_PH': './source/images/pos', 'NEG_IMG_PH': './source/images/neg', 'TEST_IMG_DIR_PH': './source/test_images'}\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_4/pos created\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_4/neg created\n",
      "==> Directory Tree ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_4 created\n",
      "==> Directory Tree ./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_4 created\n",
      "==> Calculating the descriptors for the positive samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9731/9731 [01:39<00:00, 97.42it/s]\n",
      "  1%|          | 11/2000 [00:00<00:19, 103.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Positive features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_4/pos\n",
      "==> Calculating the descriptors for the negative samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:20<00:00, 97.84it/s]\n",
      " 40%|███▉      | 134/336 [00:00<00:00, 1330.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Negative features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_4/neg\n",
      "==> Completed calculating features from training images\n",
      "==> Loading the positive features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [00:00<00:00, 1315.35it/s]\n",
      " 11%|█▏        | 228/2000 [00:00<00:00, 2275.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Load the negative features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1328.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training a Linear SVM Classifier\n",
      "==> Classifier saved to ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_4/svm.model\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_4/test_9.JPG\n",
      "(1920, 1920)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_8_PPC_4/test_8.JPG\n",
      "(2576, 1932)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2290f4590b54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mtrain_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mtest_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPROJECT_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-1427d75bb3a2>\u001b[0m in \u001b[0;36mtest_classifier\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     56\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0;31m# Calculate the HOG features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-535fd26a7e1d>\u001b[0m in \u001b[0;36mprocess_image\u001b[0;34m(image, args)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDES_TYPE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"HOG\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixels_per_cell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIXELS_PER_CELL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDES_TYPE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"LBP\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlbp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLBP_POINTS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLBP_RADIUS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/skimage/feature/_hog.py\u001b[0m in \u001b[0;36mhog\u001b[0;34m(image, orientations, pixels_per_cell, cells_per_block, block_norm, visualize, visualise, transform_sqrt, feature_vector, multichannel)\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morientation_histogram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mnormalized_blocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0m_hog_normalize_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblock_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \"\"\"\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/skimage/feature/_hog.py\u001b[0m in \u001b[0;36m_hog_normalize_block\u001b[0;34m(block, method, eps)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'L2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'L2-Hys'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#         self.MIN_WDW_SIZE = [64, 64]\n",
    "#         self.STEP_SIZE = [12, 12]\n",
    "#         self.ORIENTATIONS = 9\n",
    "#         self.PIXELS_PER_CELL = [3, 3]\n",
    "#         self.CELLS_PER_BLOCK = [3, 3]\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# def fxn():\n",
    "#     warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "for step_size in range(8,36,4):\n",
    "    for pixels_per_cell in range(3,10,1):\n",
    "        for cells_per_block in range(3, 10, 1):\n",
    "            args = Config()\n",
    "            args.STEP_SIZE = [step_size, step_size]\n",
    "            args.CELLS_PER_BLOCK = [cells_per_block, cells_per_block]\n",
    "            args.PIXELS_PER_CELL = [pixels_per_cell, pixels_per_cell]\n",
    "            args.PROJECT_ID = args.PROJECT_ID + \"_SS_\" + str(step_size) +\\\n",
    "                    \"_CPB_\" + str(cells_per_block) + \"_PPC_\" + str(pixels_per_cell)\n",
    "            args.update_names()\n",
    "            print(args.PROJECT_ID, args.DIR_PATHS)\n",
    "            args.mk_new_dirs()\n",
    "            extract_features(args=args)\n",
    "            train_classifier(args=args)\n",
    "            test_classifier(args=args)\n",
    "            if not args.KEEP_FEAT:\n",
    "                shutil.rmtree(args.DIR_PATHS['NEG_FEAT_PH'])\n",
    "                shutil.rmtree(args.DIR_PATHS['POS_FEAT_PH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing of Video-Generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = './output3/'\n",
    "outdir = ['./new_video/pos', './new_video/neg']\n",
    "dirs = os.listdir(prefix)\n",
    "negs = []\n",
    "poss = []\n",
    "for adir in dirs:\n",
    "    if adir.startswith('neg'):\n",
    "        negs.append(os.path.join(prefix, adir))\n",
    "    elif adir.startswith('pos'):\n",
    "        poss.append(os.path.join(prefix, adir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for adir in poss:\n",
    "    for img in os.listdir(adir):\n",
    "#         print(os.path.join(adir, img), os.path.join(outdir[0], img))\n",
    "        os.rename(os.path.join(adir, img), os.path.join(outdir[0], os.path.split(adir)[1]+'_'+img))\n",
    "\n",
    "for adir in negs:\n",
    "    for img in os.listdir(adir):\n",
    "#         print(os.path.join(adir, img), os.path.join(outdir[1], img))\n",
    "        os.rename(os.path.join(adir, img), os.path.join(outdir[1], os.path.split(adir)[1]+'_'+img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
