{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from skimage.feature import hog\n",
    "from skimage.feature import haar_like_feature\n",
    "from skimage.feature import local_binary_pattern as lbp\n",
    "from skimage.io import imread\n",
    "from skimage.transform import pyramid_gaussian, integral_image\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self):\n",
    "        \n",
    "        # General Config\n",
    "        self.DES_TYPE = \"HOG\"\n",
    "        self.CLF_TYPE = \"MLP\"\n",
    "        self.PROJECT_ID = \"no_hands_\" + self.DES_TYPE + self.CLF_TYPE\n",
    "        self.THRESHOLD = 0.3\n",
    "        self.DOWNSCALE = 1.25\n",
    "        \n",
    "        # Pathes\n",
    "        self.DIR_PATHS = {\n",
    "            \"POS_FEAT_PH\"    : os.path.join(\"./source/features\", self.PROJECT_ID,\"pos\"),\n",
    "            \"NEG_FEAT_PH\"    : os.path.join(\"./source/features\", self.PROJECT_ID,\"neg\"),\n",
    "            \"MODEL_DIR_PH\"   : os.path.join(\"./source/models\", self.PROJECT_ID),\n",
    "            \"POS_IMG_PH\"     : \"./source/images/pos\",\n",
    "            \"NEG_IMG_PH\"     : \"./source/images/neg\",\n",
    "            \"TEST_IMG_DIR_PH\": \"./source/test_images\"\n",
    "        }\n",
    "        self.MODEL_PH = os.path.join(self.DIR_PATHS[\"MODEL_DIR_PH\"], \"svm.model\")\n",
    "        self.TEST_IMG_PH = os.path.join(self.DIR_PATHS[\"TEST_IMG_DIR_PH\"], \"test.jpg\")\n",
    "        \n",
    "        # HOG Features\n",
    "        self.MIN_WDW_SIZE = [64, 64]\n",
    "        self.STEP_SIZE = [12, 12]\n",
    "        self.ORIENTATIONS = 9\n",
    "        self.PIXELS_PER_CELL = [3, 3]\n",
    "        self.CELLS_PER_BLOCK = [3, 3]\n",
    "        self.VISUALIZE = False\n",
    "        self.NORMALIZE = True\n",
    "        \n",
    "        # LBP Features\n",
    "        self.LBP_RADIUS = 3\n",
    "        self.LBP_POINTS = 8 * self.LBP_RADIUS\n",
    "\n",
    "args = Config()\n",
    "for ph in args.DIR_PATHS.values():\n",
    "    if not os.path.exists(ph):\n",
    "        os.makedirs(ph)\n",
    "        print(\"==> Directory Tree\",ph,\"created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image, args=args):\n",
    "    if args.DES_TYPE == \"HOG\":\n",
    "        fd = hog(image, block_norm='L2', pixels_per_cell=args.PIXELS_PER_CELL)\n",
    "    elif args.DES_TYPE == \"LBP\":\n",
    "        fd = lbp(image, args.LBP_POINTS, args.LBP_RADIUS)\n",
    "    elif args.DES_TYPE == \"HAAR\":\n",
    "        fd = haar_like_feature(integral_image(image), 0, 0, 5, 5, 'type-3-x')\n",
    "    else:\n",
    "        raise KeyError(\"==> The Processing method does not exist!\")\n",
    "    return fd\n",
    "\n",
    "def extract_features(args=args):\n",
    "    if os.path.exists(args.DIR_PATHS[\"POS_FEAT_PH\"]):\n",
    "        shutil.rmtree(args.DIR_PATHS[\"POS_FEAT_PH\"])\n",
    "    if os.path.exists(args.DIR_PATHS[\"NEG_FEAT_PH\"]):\n",
    "        shutil.rmtree(args.DIR_PATHS[\"NEG_FEAT_PH\"])\n",
    "    os.makedirs(args.DIR_PATHS[\"POS_FEAT_PH\"])\n",
    "    os.makedirs(args.DIR_PATHS[\"NEG_FEAT_PH\"])\n",
    "    \n",
    "    print(\"==> Calculating the descriptors for the positive samples and saving them\")\n",
    "    for im_path in tqdm(glob.glob(os.path.join(args.DIR_PATHS[\"POS_IMG_PH\"], \"*\"))):\n",
    "        im = imread(im_path, as_grey=True)\n",
    "        fd = process_image(im)\n",
    "        fd_name = os.path.split(im_path)[1].split(\".\")[0] + \".feat\"\n",
    "        fd_path = os.path.join(args.DIR_PATHS[\"POS_FEAT_PH\"], fd_name)\n",
    "        joblib.dump(fd, fd_path)\n",
    "    print(\"==> Positive features saved in {}\".format(args.DIR_PATHS[\"POS_FEAT_PH\"]))\n",
    "\n",
    "    print(\"==> Calculating the descriptors for the negative samples and saving them\")\n",
    "    for im_path in tqdm(glob.glob(os.path.join(args.DIR_PATHS[\"NEG_IMG_PH\"], \"*\"))):\n",
    "        im = imread(im_path, as_grey=True)\n",
    "        fd = process_image(im)\n",
    "        fd_name = os.path.split(im_path)[1].split(\".\")[0] + \".feat\"\n",
    "        fd_path = os.path.join(args.DIR_PATHS[\"NEG_FEAT_PH\"], fd_name)\n",
    "        joblib.dump(fd, fd_path)\n",
    "    print(\"==> Negative features saved in {}\".format(args.DIR_PATHS[\"NEG_FEAT_PH\"]))\n",
    "    print(\"==> Completed calculating features from training images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(args=args):\n",
    "    fds = []\n",
    "    labels = []\n",
    "    print(\"==> Loading the positive features\")\n",
    "    for feat_path in tqdm(glob.glob(os.path.join(args.DIR_PATHS[\"POS_FEAT_PH\"], \"*.feat\"))):\n",
    "        fd = joblib.load(feat_path)\n",
    "        fds.append(fd.reshape(-1))\n",
    "        labels.append(1)\n",
    "\n",
    "    print(\"==> Load the negative features\")\n",
    "    for feat_path in tqdm(glob.glob(os.path.join(args.DIR_PATHS[\"NEG_FEAT_PH\"], \"*.feat\"))):\n",
    "        fd = joblib.load(feat_path)\n",
    "        fds.append(fd.reshape(-1))\n",
    "        labels.append(0)\n",
    "\n",
    "    if args.CLF_TYPE is \"LIN_SVM\":\n",
    "        clf = LinearSVC()\n",
    "        print(\"==> Training a Linear SVM Classifier\")\n",
    "        clf.fit(fds, labels)\n",
    "        joblib.dump(clf, args.MODEL_PH)\n",
    "        print(\"==> Classifier saved to {}\".format(args.MODEL_PH))\n",
    "    elif args.CLF_TYPE is \"MLP\":\n",
    "        clf = MLPClassifier(solver='lbfgs', alpha=1e-4, hidden_layer_sizes=(16, 32, 64), random_state=1)\n",
    "        print(\"==> Training a Multi Layer Classifier\")\n",
    "        clf.fit(fds, labels)\n",
    "        joblib.dump(clf, args.MODEL_PH)\n",
    "        print(\"==> Classifier saved to {}\".format(args.MODEL_PH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def overlapping_area(detection_1, detection_2):\n",
    "    \"\"\"\n",
    "        Function to calculate overlapping area'si\n",
    "        `detection_1` and `detection_2` are 2 detections whose area\n",
    "        of overlap needs to be found out.\n",
    "        Each detection is list in the format ->\n",
    "        [x-top-left, y-top-left, confidence-of-detections, width-of-detection, height-of-detection]\n",
    "        The function returns a value between 0 and 1,\n",
    "        which represents the area of overlap.\n",
    "        0 is no overlap and 1 is complete overlap.\n",
    "        Area calculated from ->\n",
    "        http://math.stackexchange.com/questions/99565/simplest-way-to-calculate-the-intersect-area-of-two-rectangles\n",
    "    \"\"\"\n",
    "    # Calculate the x-y co-ordinates of the rectangles\n",
    "    x1_tl = detection_1[0]\n",
    "    x2_tl = detection_2[0]\n",
    "    x1_br = detection_1[0] + detection_1[3]\n",
    "    x2_br = detection_2[0] + detection_2[3]\n",
    "    y1_tl = detection_1[1]\n",
    "    y2_tl = detection_2[1]\n",
    "    y1_br = detection_1[1] + detection_1[4]\n",
    "    y2_br = detection_2[1] + detection_2[4]\n",
    "    # Calculate the overlapping Area\n",
    "    x_overlap = max(0, min(x1_br, x2_br) - max(x1_tl, x2_tl))\n",
    "    y_overlap = max(0, min(y1_br, y2_br) - max(y1_tl, y2_tl))\n",
    "    overlap_area = x_overlap * y_overlap\n",
    "    area_1 = detection_1[3] * detection_2[4]\n",
    "    area_2 = detection_2[3] * detection_2[4]\n",
    "    total_area = area_1 + area_2 - overlap_area\n",
    "    return overlap_area / float(total_area)\n",
    "\n",
    "\n",
    "def nms(detections, threshold=.5):\n",
    "    \"\"\"\n",
    "        This function performs Non-Maxima Suppression.\n",
    "        `detections` consists of a list of detections.\n",
    "        Each detection is in the format ->\n",
    "        [x-top-left, y-top-left, confidence-of-detections, width-of-detection, height-of-detection]\n",
    "        If the area of overlap is greater than the `threshold`,\n",
    "        the area with the lower confidence score is removed.\n",
    "        The output is a list of detections.\n",
    "    \"\"\"\n",
    "    if len(detections) == 0:\n",
    "        return []\n",
    "    # Sort the detections based on confidence score\n",
    "    detections = sorted(detections, key=lambda detections: detections[2],\n",
    "                        reverse=True)\n",
    "    new_detections = [] # Unique detections will be appended to this list\n",
    "    new_detections.append(detections[0]) # Append the first detection\n",
    "    del detections[0] # Remove the detection from the original list\n",
    "    \"\"\"\n",
    "        For each detection, calculate the overlapping area\n",
    "        and if area of overlap is less than the threshold set\n",
    "        for the detections in `new_detections`, append the \n",
    "        detection to `new_detections`.\n",
    "        In either case, remove the detection from `detections` list.\n",
    "    \"\"\"\n",
    "    for index, detection in enumerate(detections):\n",
    "        for new_detection in new_detections:\n",
    "            if overlapping_area(detection, new_detection) > threshold:\n",
    "                del detections[index]\n",
    "                break\n",
    "        else:\n",
    "            new_detections.append(detection)\n",
    "            del detections[index]\n",
    "    return new_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_by_short(img, short_len=256):\n",
    "    print(img.size)\n",
    "    (x, y) = img.size\n",
    "    if x > y:\n",
    "        y_s = short_len\n",
    "        x_s = int(x * y_s / y)\n",
    "        img = img.resize((x_s, y_s))\n",
    "    else:\n",
    "        x_s = short_len\n",
    "        y_s = int(y * x_s / x)\n",
    "        img = img.resize((x_s, y_s))\n",
    "    return img\n",
    "\n",
    "\n",
    "def sliding_window(image, window_size, step_size):\n",
    "    \"\"\"\n",
    "        This function returns a patch of the input image `image` of size equal\n",
    "        to `window_size`. The first image returned top-left co-ordinates (0, 0)\n",
    "        and are increment in both x and y directions by the `step_size` supplied.\n",
    "        So, the input parameters are -\n",
    "        * `image` - Input Image\n",
    "        * `window_size` - Size of Sliding Window\n",
    "        * `step_size` - Incremented Size of Window\n",
    "\n",
    "        The function returns a tuple -\n",
    "        (x, y, im_window)\n",
    "        where\n",
    "        * x is the top-left x co-ordinate\n",
    "        * y is the top-left y co-ordinate\n",
    "        * im_window is the sliding window image\n",
    "    \"\"\"\n",
    "    for y in range(0, image.shape[0], step_size[1]):\n",
    "        for x in range(0, image.shape[1], step_size[0]):\n",
    "            yield (x, y, image[y:y + window_size[1], x:x + window_size[0]])\n",
    "\n",
    "\n",
    "def test_classifier(args=args):\n",
    "    # Read the Image\n",
    "    im = Image.open(args.TEST_IMG_PH).convert('L')\n",
    "    im = np.array(resize_by_short(im))\n",
    "\n",
    "    clf = joblib.load(args.MODEL_PH) # Load the classifier\n",
    "    detections = [] # List to store the detections\n",
    "    scale = 0 # The current scale of the image\n",
    "    \n",
    "    # Downscale the image and iterate\n",
    "    for im_scaled in pyramid_gaussian(im, downscale=args.DOWNSCALE):\n",
    "        cd = [] # This list contains detections at the current scale\n",
    "        # If the width or height of the scaled image is less than\n",
    "        # the width or height of the window, then end the iterations.\n",
    "        if im_scaled.shape[0] < args.MIN_WDW_SIZE[1] or im_scaled.shape[1] < args.MIN_WDW_SIZE[0]:\n",
    "            break\n",
    "        for (x, y, im_window) in sliding_window(im_scaled, args.MIN_WDW_SIZE, args.STEP_SIZE):\n",
    "            if im_window.shape[0] != args.MIN_WDW_SIZE[1] or im_window.shape[1] != args.MIN_WDW_SIZE[0]:\n",
    "                continue\n",
    "            # Calculate the HOG features\n",
    "            fd = process_image(im_window).reshape([1, -1])\n",
    "            pred = clf.predict(fd)\n",
    "            if pred == 1:\n",
    "                print(\"==> Detection:: Location -> ({}, {})\".format(x, y))\n",
    "                if args.CLF_TYPE is \"LIN_SVM\":\n",
    "                    print(\"==> Scale ->  {} Confidence Score {} \\n\".format(scale, clf.decision_function(fd)))\n",
    "                    detections.append((x, y, clf.decision_function(fd),\n",
    "                                       int(args.MIN_WDW_SIZE[0] * (args.DOWNSCALE ** scale)),\n",
    "                                       int(args.MIN_WDW_SIZE[1] * (args.DOWNSCALE ** scale))))\n",
    "                elif args.CLF_TYPE is \"MLP\":\n",
    "                    print(\"==> Scale ->  {} Confidence Score {} \\n\".format(scale, clf.predict_proba(fd)[0][1]))#clf.decision_function(fd)))\n",
    "                    detections.append((x, y, clf.predict_proba(fd)[0][1],\n",
    "                                       int(args.MIN_WDW_SIZE[0] * (args.DOWNSCALE ** scale)),\n",
    "                                       int(args.MIN_WDW_SIZE[1] * (args.DOWNSCALE ** scale))))\n",
    "                cd.append(detections[-1])\n",
    "                \n",
    "            # If visualize is set to true, display the working of the sliding window\n",
    "            if args.VISUALIZE:\n",
    "                clone = im_scaled.copy()\n",
    "                for x1, y1, _, _, _ in cd:\n",
    "                    # Draw the detections at this scale\n",
    "                    cv2.rectangle(clone, (x1, y1), (x1 + im_window.shape[1], y1 +\n",
    "                                                    im_window.shape[0]), (0, 0, 0), thickness=2)\n",
    "                cv2.rectangle(clone, (x, y), (x + im_window.shape[1], y +\n",
    "                                              im_window.shape[0]), (255, 255, 255), thickness=2)\n",
    "                cv2.imshow(\"Sliding Window in Progress\", clone)\n",
    "                cv2.waitKey(30)\n",
    "        \n",
    "        # Move the the next scale\n",
    "        scale += 1\n",
    "\n",
    "    # Display the results before performing NMS\n",
    "    clone = im.copy()\n",
    "    \n",
    "    # Draw the detections\n",
    "    for (x_tl, y_tl, _, w, h) in detections:\n",
    "        cv2.rectangle(im, (x_tl, y_tl), (x_tl + w, y_tl + h), (0, 0, 0), thickness=2)\n",
    "    \n",
    "    detections = nms(detections, args.THRESHOLD) # Perform Non Maxima Suppression\n",
    "\n",
    "    # Display the results after performing NMS\n",
    "    for (x_tl, y_tl, _, w, h) in detections:\n",
    "        # Draw the detections\n",
    "        cv2.rectangle(clone, (x_tl, y_tl), (x_tl + w, y_tl + h), (0, 0, 0), thickness=2)\n",
    "    cv2.imshow(\"Final Detections after applying NMS\", clone)\n",
    "    cv2.imwrite('test1.jpg', clone)\n",
    "    cv2.waitKey()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2320, 2316)\n",
      "==> Detection:: Location -> (0, 0)\n",
      "==> Scale ->  0 Confidence Score 0.7203061704991643 \n",
      "\n",
      "==> Detection:: Location -> (168, 0)\n",
      "==> Scale ->  0 Confidence Score 0.6792623854887551 \n",
      "\n",
      "==> Detection:: Location -> (180, 0)\n",
      "==> Scale ->  0 Confidence Score 0.9968393097996824 \n",
      "\n",
      "==> Detection:: Location -> (192, 0)\n",
      "==> Scale ->  0 Confidence Score 0.999438568123085 \n",
      "\n",
      "==> Detection:: Location -> (180, 12)\n",
      "==> Scale ->  0 Confidence Score 0.9982739187515445 \n",
      "\n",
      "==> Detection:: Location -> (192, 12)\n",
      "==> Scale ->  0 Confidence Score 0.870490685374699 \n",
      "\n",
      "==> Detection:: Location -> (192, 24)\n",
      "==> Scale ->  0 Confidence Score 0.9485256855327758 \n",
      "\n",
      "==> Detection:: Location -> (192, 36)\n",
      "==> Scale ->  0 Confidence Score 0.9206986358901351 \n",
      "\n",
      "==> Detection:: Location -> (192, 48)\n",
      "==> Scale ->  0 Confidence Score 0.9937408189038683 \n",
      "\n",
      "==> Detection:: Location -> (192, 60)\n",
      "==> Scale ->  0 Confidence Score 0.9975999382021522 \n",
      "\n",
      "==> Detection:: Location -> (192, 72)\n",
      "==> Scale ->  0 Confidence Score 0.999948227466251 \n",
      "\n",
      "==> Detection:: Location -> (192, 84)\n",
      "==> Scale ->  0 Confidence Score 0.9998459079536551 \n",
      "\n",
      "==> Detection:: Location -> (72, 96)\n",
      "==> Scale ->  0 Confidence Score 0.9965816053240427 \n",
      "\n",
      "==> Detection:: Location -> (84, 96)\n",
      "==> Scale ->  0 Confidence Score 0.5602996674085972 \n",
      "\n",
      "==> Detection:: Location -> (192, 96)\n",
      "==> Scale ->  0 Confidence Score 0.9999662166038069 \n",
      "\n",
      "==> Detection:: Location -> (192, 108)\n",
      "==> Scale ->  0 Confidence Score 0.999699101442054 \n",
      "\n",
      "==> Detection:: Location -> (192, 120)\n",
      "==> Scale ->  0 Confidence Score 0.8291918416355808 \n",
      "\n",
      "==> Detection:: Location -> (96, 192)\n",
      "==> Scale ->  0 Confidence Score 0.5571259844755868 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miracle/anaconda2/envs/py3/lib/python3.6/site-packages/skimage/transform/_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Detection:: Location -> (60, 60)\n",
      "==> Scale ->  1 Confidence Score 0.9895157622533352 \n",
      "\n",
      "==> Detection:: Location -> (48, 120)\n",
      "==> Scale ->  1 Confidence Score 0.5315719798769571 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miracle/anaconda2/envs/py3/lib/python3.6/site-packages/skimage/transform/_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Detection:: Location -> (48, 48)\n",
      "==> Scale ->  2 Confidence Score 0.9937730700420631 \n",
      "\n",
      "==> Detection:: Location -> (36, 96)\n",
      "==> Scale ->  2 Confidence Score 0.9994495771057167 \n",
      "\n",
      "==> Detection:: Location -> (48, 96)\n",
      "==> Scale ->  2 Confidence Score 0.9999738484598175 \n",
      "\n",
      "==> Detection:: Location -> (24, 0)\n",
      "==> Scale ->  3 Confidence Score 0.9903153420090779 \n",
      "\n",
      "==> Detection:: Location -> (24, 12)\n",
      "==> Scale ->  3 Confidence Score 0.7379637050371173 \n",
      "\n",
      "==> Detection:: Location -> (36, 24)\n",
      "==> Scale ->  3 Confidence Score 0.7286311189494047 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miracle/anaconda2/envs/py3/lib/python3.6/site-packages/skimage/transform/_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n",
      "/Users/miracle/anaconda2/envs/py3/lib/python3.6/site-packages/skimage/transform/_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n",
      "/Users/miracle/anaconda2/envs/py3/lib/python3.6/site-packages/skimage/transform/_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n",
      "/Users/miracle/anaconda2/envs/py3/lib/python3.6/site-packages/skimage/transform/_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n",
      "/Users/miracle/anaconda2/envs/py3/lib/python3.6/site-packages/skimage/transform/_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Detection:: Location -> (12, 36)\n",
      "==> Scale ->  4 Confidence Score 0.9766710083451909 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract_features()\n",
    "# train_classifier()\n",
    "test_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = joblib.load(args.MODEL_PH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ClassifierMixin.score of MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(16, 32, 64), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Detection:: Location -> (144, 72)\n",
    "Scale ->  1 Confidence Score [0.22061759] \n",
    "\n",
    "Detection:: Location -> (132, 96)\n",
    "Scale ->  1 Confidence Score [0.17914904] \n",
    "\n",
    "Detection:: Location -> (132, 108)\n",
    "Scale ->  1 Confidence Score [0.01408734] \n",
    "\n",
    "Detection:: Location -> (132, 120)\n",
    "Scale ->  1 Confidence Score [0.17246304] \n",
    "\n",
    "Detection:: Location -> (132, 132)\n",
    "Scale ->  1 Confidence Score [0.10221041] \n",
    "\n",
    "Detection:: Location -> (144, 132)\n",
    "Scale ->  1 Confidence Score [0.22871] \n",
    "\n",
    "Detection:: Location -> (120, 24)\n",
    "Scale ->  2 Confidence Score [0.27871952] \n",
    "\n",
    "Detection:: Location -> (108, 60)\n",
    "Scale ->  2 Confidence Score [0.00498687] \n",
    "\n",
    "Detection:: Location -> (108, 72)\n",
    "Scale ->  2 Confidence Score [0.10781702] \n",
    "\n",
    "Detection:: Location -> (108, 84)\n",
    "Scale ->  2 Confidence Score [0.00505348] \n",
    "\n",
    "Detection:: Location -> (108, 96)\n",
    "Scale ->  2 Confidence Score [0.18474691] \n",
    "\n",
    "Detection:: Location -> (96, 12)\n",
    "Scale ->  3 Confidence Score [0.2362471] \n",
    "\n",
    "Detection:: Location -> (84, 60)\n",
    "Scale ->  3 Confidence Score [0.06845096] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
